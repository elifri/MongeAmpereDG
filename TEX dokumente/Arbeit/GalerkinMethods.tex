\subsection*{Vor체berlegungen zu Galerkin}

\[
\int_\Omega F(D^2 u_h, \nabla u_h, u_h, x)v_h dx = 0
\]

Damit diese Formulierung Sinn macht, sollten die FE-R채ume $C^1$ sein.
F체r Brenner ist wichtig, dass Linearisieren und Diskretisieren kommutativ sind (bei $C^1$ der Fall, im Paper \cite{Brenner2012} erzwingt sie es f체r $C^0$) sonst ist das Verfahren instabil.

ACHTUNG:
\[
\sum_{T \in \mathcal{T}_h} \int_T(f-Det(D^2 u_h))v_h dx = 0 \qquad \forall v_h \in V_h \cap H_0^1(\Omega)
\]



\section{State of the Art for Discontinuous Galerkin Methods} % for the \MA equation}

The most natural attempt for a formulation of a DG method is to exploit the equations
\begin{align}
	\int_{\Omega} \mydet {D^2 u} v = \int_\Omega fv, \qquad \text{ for all test functions } v. \label{eq: naiv ansatz}
\end{align}

However, this formulation has two minor disadvantages. 
At first we cannot throw the high derivatives onto the test functions using integration py parts, thus we do not easily get a variational formulation as we do for linear PDEs. Secondly \eqref{eq: naiv ansatz} only is sensible for test and ansatz functions contained in $C^1(\Omega)$. An extension with the natural DG terms which would allow less regular functions does not produce sensible results. Brenner et alter make the inconsistency between the linearisation of the discrete problem and the the linearisation of the continuous problem responsible \cite{BGN+2011} for this failure. Thus, their idea is to add terms to force consistency and add stability.

\subsection{A $C^0$ Penalty Method }

The linearisation of the left-hand side of \eqref{eq: naiv ansatz} is given by the bilinear form
\begin{align}
\langle L_{u,h}(w_h),v_h\rangle = \int_{\Omega} \left( \mycof{D^2 u_h} \nabla w_h\right) \cdot \nabla v_h. \label{linearOperator}
\end{align}
\todo{proof}

%operator is
%\begin{align}
%\langle L_{u,h}(w_h),v_h\rangle = \int_{\Omega} \left( \mycof{D^2 u_h} \nabla w_h\right) \cdot \nabla v_h. %\label{linearOperator}
%\end{align}
%Using the divergence product rule we get 
%\[
%   \mycof{D^2 u_h}:D^2 w_h  = \nabla \cdot (\mycof{D^2 u_h} \nabla w_h) - (\nabla \cdot \mycof{D^2 u_h}) \nabla w_h,
%\]
%which simplifies by the divergence free property of the cofactor matrix to
%\begin{align*}
%   \mycof{D^2 u_h}:D^2 w_h  &= \nabla \cdot (\mycof{D^2 u_h} \nabla w_h).
%\end{align*}
Due to integration by parts it holds
\begin{align*}
  \int_T \nabla \cdot (\mycof{D^2 u_h} \nabla w_h) v_h= -\int_T (\mycof{D^2 u_h} \nabla w_h) \nabla v_h+ \int_{\partial T} (\mycof{D^2 u_h} \nabla w_h) v_h.
\end{align*}
Summing over the whole triangulation it becomes
\begin{align*}
  \int_\Omega \nabla \cdot (\mycof{D^2 u_h} \nabla w_h) v_h= -\int_\Omega (\mycof{D^2 u_h} \nabla w_h) \nabla v_h+ \sum_{e \in \edges} \int_{e} \llbracket \{\{\mycof{D^2 u_h} \}\} \nabla w_h\rrbracket v_h.
\end{align*}

Setting this in \eqref{linearOperator} yields 
\begin{align*}
	\langle L_{u,h}(w_h),v_h\rangle 
	     &=- \sum_{T \in \triang}  \int_T \nabla \cdot (\mycof{D^2 u_h} \nabla w_h) v_h
	    + \sum_{e \in \edges} \int_{e} \llbracket \{\{\mycof{D^2 u_h} \}\} \nabla w_h\rrbracket v_h
\end{align*}
The aim is this bilinear form to be consistent and stable with the linearisation of the \MA equation. Hence, Brenner et al. gain the improved bilinearform
\begin{align*}
	\langle L^B_{u,h}(w_h),v_h\rangle 
	    =&- \sum_{T \in \triang}  \int_T \nabla \cdot (\mycof{D^2 u_h} \nabla w_h) v_h
	    + \sum_{e \in \edges} \int_{e} \llbracket \{\{\mycof{D^2 u_h} \}\} \nabla w_h\rrbracket v_h \\
	    &+ \sum_{e \in \edges} \int_{e} \llbracket \{\{\mycof{D^2 u_h} \}\} \nabla v_h\rrbracket w_h
\end{align*}
Plugging the newly derived terms of the enhanced bilinearform into the original naive ansatz \eqref{eq: naiv ansatz} and adding further terms to enforce weak boundary conditions they formulate the problem: Find $u_h \in V_h$ such that
\begin{align}
\begin{split}
	&\int_{\Omega} (f-\mydet {D^2_h u_h} v 
	+ \sum_{e \in \edgesi} \int_{e} \llbracket \{\{\mycof{D^2 u_h} \}\} \nabla u_h\rrbracket v_h \\
	&- \sum_{e \in \edgesb} \int_{e} \llbracket \{\{\mycof{D^2 u_h} \}\} \nabla v_h\rrbracket (u_h -g) 
	+ \sigma  \sum_{e \in \edgesb} \frac 1 {h_e} \int_{e} (u_h -g)  = 0 \; \forall v_h \in V_h \label{eq: brenner method}
\end{split}
\end{align}
They choose their ansatz and test space $V_h$ to be the space of continuous functionous being piecewise polynomials up to degree $k$ for a $k \geq 3$. For this case they provide a detailed analysis consisting of a proof of well-posedness and some error estimates. Their numerical results suggest convergence rates \todo{convergence rates} although they cannot confirm those with theoretical evidence. \\
However, their approach has a drawback. In order to find $u_h$ one has to solve the from \eqref{eq: brenner method} resulting nonlinear system. Brenner et alt. make use of Newton's method in the numerical results to solve their example problems. For a good initial guess they inquire a vanishing moments method which internally again solves nonlinear systems based on a Newton's method which uses a nested iteration to create initial guesses. 

We implemented their presented method using the finite element tool FEniCS \cite{FEniCS} and experienced a huge sensitivity for initial starting points.
\todo{tolle numerische ergebnisse}

Neilan claims when presenting his method in \cite{Neilan2014} that this methods fails to converge for the test case
$u = -\sqrt{2 - x_1^2 - x_2^2 }$ and $f = \frac 2 {{2 - x_1^2 - x_2^2}^2}$. Generally the presented method is more appropriate for classical solutions, they plan to address less regular solution in future work.


\subsection{A Finite Element Method based on a Discrete Hessian} \label{subsec: disrete Hessian} \label{sec: FEM discrete Hessian}

Shortly Neilan generalised a finite element method of Lakkis and Pryer \cite{LP2011} in his paper \cite{Neilan2014}.
The crux of this idea is the notion of a \emph{discrete Hessian}. 
While the real Hessian fulfills due to integration by parts as we have seen in Lemma \ref{la: integration by parts Frobenius}
	\begin{align}
		\int_\Omega (D^2 u : B) = - \int_\Omega \left(\nabla \cdot B\right) \cdot \nabla u + \int_{\partial \Omega}  B \nabla u \mathbf {n} \qquad \forall B \in [H^1(\Omega)]^{d \times d}, \label{eq: part int hessian}
	\end{align}
often the ansatz spaces $V_h$ are not regular enough such that $D_h^2 v$ for $ v \in V_h$ does not inherit this property. Considering that most weak formulations base on a integration of a multiplication with a test function, the idea of a discretisation of the Hessian retaining this quality was born.
To create this discretisation he integrates \eqref{eq: part int hessian} piecewise on every triangle and rewrite as usual the edge terms by a combination of jump and averages leading to
	\begin{align}
		\begin{split}
		\int_\Omega (D^2 u : B) 
		=& - \int_\Omega \left(\nabla \cdot B\right) \cdot \nabla u \\
		&+ \sum_{ e \in \edgesi} \int_e  \jump {\average B \nabla u }
				+ \sum_{ e \in \edges} \int_e  \jump{B \average {\nabla u} }  \qquad \forall B \in \Sigma_h. \label{eq: part int hessian omega}
		\end{split}
	\end{align}
Observing, that the last step admits more possible test functions $B$, Neilan suggests the ansatz space $V_h = \mathcal{P}_h^k \cap H^1(\Omega)$ and the test space $\Sigma_h = [\mathcal{P}_h^k]^{d \times d}$.

Substituting in \eqref{eq: part int hessian omega} $\nabla u$ across the edges with its numerical counterpart, namely the numerical trace chosen as $\laverage \nabla u \raverage$ one has as predefinition of the discrete Hessian
	\begin{align}
		\int_\Omega (D_{DH}^2 u : B) 
		&= - \int_\Omega \left(\nabla \cdot B\right) \cdot \nabla u
		+ \sum_{ e \in \edgesi} \int_e  \jump {\average B \nabla u } 
				+ \sum_{ e \in \edges} \int_e \jump {B \average {\nabla u} }  \nonumber \\
		&= - \int_\Omega \left(\nabla \cdot B\right) \cdot \nabla u
				+ \sum_{ e \in \edges} \int_e  \jump{B \average {\nabla u} }.	
	\end{align}
Applying once more integration by parts for a Frobenius product on every triangle in the integral on the right-hand side results in
	\begin{align}
		\int_\Omega (D_{DH}^2 u : B) 
		=& \int_\Omega D_h u: B 
			-\sum_{ e \in \edgesi} \int_e  \jump {\average B  \nabla u }
			- \sum_{ e \in \edges} \int_e \jump {B \average {\nabla u} }\nonumber \\		
			&+ \sum_{ e \in \edges} \int_e  \jump {B \average {\nabla u} }		\nonumber \\
		=& \int_\Omega D_h u: B -\sum_{ e \in \edgesi} \int_e  \jump {\average B  \nabla u }				
	\end{align}

Hence,
\begin{definition}[Discrete Hessian]
	The discrete Hessian $D_{DH}^2 u$ of a function $u$ is the unique function satisfying
	\begin{align}
		\int_\Omega (D_{DH}^2 u : B) 
		= \int_\Omega D_h u: B -\sum_{ e \in \edgesi} \int_e  \jump {\average B \nabla u }\qquad \forall B \in \Sigma_h. \label{eq: discrete hessian}
	\end{align}
\end{definition}

Even though the Hessian is symmetric, in general the discrete Hessian is owing to the face terms not obligatory symmetric. \\
Note, that for a discontinuous $\Sigma_h$ the computations for $D_{DH}^2 u$ reduce to purely local efforts. For piecewise constant space $\Sigma_h$ the discrete Hessian $D_{DH}^2 u$ can even be computed explicitly.

The next natural step is to plug the newly deduced Hessian into the original \MA PDE resulting in the method: Find $u \in V_h$ such that

\begin{align}
		\int_\Omega \left(\mydet{D_{DH}^2 u} - f \right) v = 0 \qquad \forall v \in V_h
\end{align}
where
	\begin{align}
		\int_\Omega (D_{DH}^2 u : B) 
		= \int_\Omega D_h u: B -\sum_{ e \in \edgesi} \int_e  \jump {\average B \nabla u }\qquad \forall B \in \Sigma_h. \eqref{eq: discrete hessian}
	\end{align}

Neilan shows the well-posedness and optimal error estimates of this methods for $k \geq 3$. Albeit he cannot prove it his numerical experiments suggest that it even works for smaller polynomial degrees. Although for $k=1$ he had to add an additional penalty term forcing thereby a smooth gradient to obtain convergence.

He does not present any proofs for convergence rates, but in the numerical results his method performs with optimal convergence rates. We check the performance of this algorithms later in chapter \ref{ch:NumericalResults}.