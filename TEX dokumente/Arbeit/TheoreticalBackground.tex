\todo{explain $\Omega$}

\begin{definition}
 A \emph{partial differential equation} (PDE) of order $k\in \N$ is an expression of the form
\begin{align}
	F(D^k(u(x)), D^{k-1}(u(x)), Du(x), u(x), x) = 0, \label{eq:general PDE}
\end{align}
where $F$ is given and $u$ is unknown.
\end{definition}


\begin{definition}[elliptic PDE]
	A PDE is called \emph{elliptic} if 
	
\end{definition}

A function $u$ fulfilling \eqref{eq:general PDE} is called a classical solution of the PDE.

There are problems such that no such solution exists, often the demand on the high derivatives cannot be fulfilled. To admit less regular solutions we aim for a weaker solution notion.


\section{Functional spaces}

According to the literature we refer by $W^{s,p}(\Omega)$ to the H\"older space, a set consisting of all $L^p(\Omega)$ functions whose distributional derivates up to order $s$ are contained in $L^ p(\Omega)$.

Let $\triang$ be a shape regular, quasi-uniform simplicial triangulation of $\Omega$. We divide its edges $\edges$ into the subsets $\edgesi$ and $\edgesb$ containing all interior edges and boundary edges, respectively.
Using that we define the piecewise spaces
\todo{piecewise spaces}
\begin{definition}[Piecewise Polynomial Spaces] \label{def: piecewise polySpace}
	Further we denote the finite-dimensional space of piecewise polynomials by
\[	
	\mathcal P^k_h = \{ f \in L^\infty(\Omega); f \arrowvert_T \textnormal{ is a polynomial of (total) degree } \leq k \textnormal{ for every } t \in \mathcal T_h\}.
\]
\end{definition}

\todo{norms}
We use a subscript $h$ to indicate a piecewise evaluation/interpretation. Subsequently differential operators with a subscript $h$ imply separate differentiations on every triangle.


\section{Notation}

To formulate a method capable of discontinuities along triangle edges we need some edge operators.   

\begin{definition}[Edge Operators]
We denote the \emph{normal jump} of  a piecewise smooth function $u_h$ across an edge $e \in \edges$ by
\begin{align*}
	\llbracket u_h \rrbracket &= u_h^+ \cdot n^+ + u_h^-\cdot n^-  &&\text{ if } \partial T^+ \cap \partial T^- = e, \\
	\llbracket u_h \rrbracket &= u_h \cdot n  &&\text{ if } \partial T \cap \partial \Omega = e,
\end{align*}
where $n^\pm$ are the outward unit normals of $T^\pm$ and  $u_h^\pm(x) = \lim_{\varepsilon \rightarrow 0} u_h(x-n^\pm \varepsilon)$.

The \emph{average} of a piecewise smooth function $u_h$ across an edge $e \in \edges$ is defined by
\begin{align*}
	\laverage u_h \raverage &= \frac 1 2 \left(u_h^+ + u_h^-\right) &&\text{ if } \partial T^+ \cap \partial T^- = e, \\
	\laverage u_h  \raverage &= u_h &&\text{ if } \partial T \cap \partial \Omega = e,
\end{align*}
\end{definition}

Note, that the jump of a scalar is a vector, whereas the jump of a vector is a scalar.


\section{Finite Element Method}
Before we handle the \MA equation we recall how a finite element method works using the example of the general Poisson equation. 

%\subsection{The Poisson Problem}

\begin{definition}[Generalised Poisson Problem]
The \emph{Generalised Poisson Problem} is finding a function $u$ such that 
\begin{align}
	-\nabla \cdot (A \nabla u) = f \qquad &\text{ in }\Omega \label{eq: poisson eq} \\
	u = g \qquad &\text{ on } \partial \Omega    \label{eq: poisson bc}
\end{align}
for $ A \in ???(\Omega)^{d \times d}$ a function $f \in ???(\Omega)$ and a function $g \in ??(\partial \Omega)$. 
\end{definition}

This problem is well-posed \todo{definition of well-posedness} for $f$ and there even exist closed solution formulas, for a detailed analysis we recommend \todo{theory poisson equation} \cite{evans1998}.
Nevertheless, we can set up a weak formulation based on variational principles.

Due to the main theorem of variation analysis \eqref{eq: poisson eq} is equivalent to 
\begin{align}
	-\int_\Omega \varphi \nabla \cdot (A \nabla u) = \int_\Omega \varphi f \qquad \forall \varphi \in C^\infty(\Omega).
\end{align}
Integration by parts yields to
\begin{align}
	\int_\Omega \nabla \varphi  \cdot A\nabla u -\int_{\partial \Omega} \varphi (A\nabla u) \mathbf{n}  = \int_\Omega \varphi f \qquad \forall \varphi \in C^\infty(\Omega). \label{eq: FE integration by parts}
\end{align}

We see, that now only first derivatives of $u$ appear on the left-hand side.   
The main idea of the finite element method is to restrict the two spaces, namely the space where $\varphi$ and the space where $u$ is searched  to finite dimensional spaces $\Phi_h$ and $V_h$ of $C^\infty(\Omega)$.\\
The limited space $\Phi_h$ is called \emph{test space} and its inhabitants :) are called \emph{test functions}. $V_h$ is referred as \emph{ansatz} or \emph{trial space},  the contained functions accordingly \emph{ansatz} or \emph{trial functions}. To assert the boundary condition \eqref{eq: poisson bc} we demand $u_h|_{\partial \Omega} = g$ for every $u_h \in V_h$.

As the subscript $h$ suggests the two spaces normally are based on a triangulation $\triang$ such that every function is at least piecewise smooth. Consequently, the differential operators must be replaced by to $\Phi_h \cup V_h$ extended forms.

All in all the finite element methods searches for $u_h \in V_h$ such that 
\begin{align}
	\int_\Omega \nabla_h \varphi  \cdot A\nabla_h u_h -\int_{\partial \Omega} \varphi  \cdot (A\nabla_h u_h) \mathbf{n}  = \int_\Omega \varphi f \qquad \forall \varphi \in \Phi_h. \label{eq: weak formulation fe}
\end{align}

To construct $u_h$ we first choose a basis $B_{\Phi}$ of $\Phi$ and a basis $B_V$ of $V_h$.
Since the left-hand side is linear in $\varphi$ we only need to check the equations in \eqref{eq: weak formulation fe} for all $\varphi \in B_{\Phi}$. Exploiting also the linearity in $u_h$  we are able to reformulate the equations using approriate bilinear forms:
\begin{align}
	a(\varphi,u_h)  =b(\varphi) \qquad \forall \varphi \in \Phi_h. \label{eq: weak formulation fe bilinear}
\end{align}
for $a(v,w)= \int_\Omega \nabla_h v  \cdot A\nabla_h w -\int_{\partial \Omega} v (A\nabla_h w)\mathbf{n}$ and $b(v) = \int_\Omega v f$.\\
Using basic linear Algebra we can rewrite \eqref{eq: weak formulation fe bilinear} as a linear system of equations $A \mathbf{u} = \mathbf{b}$ where  $\mathbf{u}$ is the coefficient vector of $u_h$ to the basis $B_V$.  

Typically the spaces $\Phi_h$ and $V_h$ are chosen to be piecewise polynomials which have support only on a few triangles. Thus, the spaces are easy to handle and the resulting linear system is sparse.
Choosing $\Phi_h = V_h$ yields to the \emph{Galerkin methods}.

\section{Discontinuous Galerkin (DG)} \label{sec: SIPG}
A recent idea is to choose the test and ansatz spaces to include discontinuous functions (even though the solution is expected to be smooth)\todo{kommentar sinnvoll}.
The main issue is the handling of derivatives along discontinuities.
\todo{DG mit numerischen Flux oder mehr wie TICAM?}

We recall our triangulation $\mathcal{T}_h$ of $\Omega$. We are able to use $\mathcal V_h = \mathcal P_h^k$ as defined in \ref*{def: piecewise polySpace} for the ansatz and test space in a finite element method, if we modify the procedure a bit: Due to the discontinuities along edges we perform the integration by parts in \eqref{eq: FE integration by parts} piecewise on every triangle leading to
\begin{align}
	a(\varphi, v) = & \sum_{T \in \triang} \int_T \nabla \varphi \cdot A \nabla v - \sum_{T \in \triang} \int_{\partial T} \varphi A \nabla v \cdot \mathbf n.
\end{align}
Since two adjacent elements share the same edge only with opposite normal vectors we can rewrite the middle term by
\begin{align*}
\sum\limits_{T \in \triang}\int_{\partial T} \varphi A \nabla v \cdot \mathbf n 
= &\sum\limits_{e \in \edgesi}\int_{e} \left( \varphi^+ A^+ \nabla v^+ \cdot \mathbf n - \varphi^- A^- \nabla v^- \cdot \mathbf n \right) \\
& + \sum\limits_{e \in \edgesb}\int_{e} \varphi A \nabla v \cdot \mathbf n,
\end{align*}
where $x^\pm $ is $x$ evaluated in one of the two adjadecent elements $T^\pm$. With the formula $ac-bd = \frac 1 2 (a+b)(c-d) + \frac 1 2 (a-b)(c+d)$ we get
\begin{align*}
	&\varphi^+ A^+ \nabla v^+ \cdot \mathbf n - \varphi^- A^- \nabla v^- \cdot \mathbf n \\
	= & \phantom{+} \frac 1 2 \left(\varphi^+ + \varphi^- \right) \left(A^+ \nabla v^+ \cdot \mathbf n - A^- \nabla v^- \cdot \mathbf n \right) \\
  &+  \frac 1 2 \left(\varphi^+ - \varphi^- \right) \left(A^+ \nabla v^+ \cdot \mathbf n + A^- \nabla v^- \cdot \mathbf n \right) \\
  = &  \average \varphi \jump { A \nabla v \cdot \mathbf n }+ \jump \varphi \average{ A \nabla v \cdot  \mathbf n }
\end{align*}
Therefore the weak formulation can be written as $a(v,\varphi) = l(\varphi)$ with 
\begin{align*}
  a(v, \varphi) = & \sum\limits_{T \in \triang} \int_T \nabla \varphi \cdot \left(A \nabla v\right) \\
	& - \sum\limits_{e \in \edgesi}\int_{e} \left( \average \varphi \jump {A \nabla v \cdot \mathbf n } + \jump \varphi \average{ A \nabla v \cdot \mathbf n } \right)\\
& - \sum\limits_{e \in \edgesb}\int_{e} \varphi A \nabla v \cdot \mathbf n
\end{align*}
and
\[
l(\varphi) = \sum_{T \in \triang} \int_T v f
\]
Due to the smoothness of $u$ and $w$ we can neglect the jump in $A \nabla u$
\begin{align*}
 a(v, \varphi) = & \sum\limits_{T \in \triang} \int_T \nabla \varphi \cdot \left(A \nabla v\right) %\\
	- \sum\limits_{e \in \edgesi}
	\jump \varphi \average{ A \nabla v \cdot \mathbf n } %\right)
	\\
& - \sum\limits_{e \in \edgesb}\int_{e} \varphi A \nabla v \cdot \mathbf n.
\end{align*}

Symmetrising our bilinear form $a$ by adding terms on both sides we have
\begin{align}
 a_S(v, \varphi) = &\sum\limits_{T \in \triang} \int_T \nabla \varphi \cdot A \nabla v \nonumber \\
  &-\sum\limits_{e \in \edgesi}\int_{e} \jump \varphi \average{A \nabla v \cdot \mathbf n } 
 - \sum\limits_{e \in \edgesi}\int_{e} \jump v \average{ A \nabla \varphi \cdot \mathbf n } \nonumber\\ 
 & - \sum\limits_{e \in \edgesb}\int_{e} \varphi A \nabla v \cdot \mathbf n 
    - \sum\limits_{e \in \edgesb}\int_{e} v A \nabla \varphi \cdot \mathbf n.
\end{align}
and 
\begin{align}
	l(\varphi) =& \sum\limits_{T \in \triang} \int_T \varphi f -\sum\limits_{e \in \edgesb}\int_{e} u_0 A \nabla \varphi \cdot \mathbf n.
\end{align} 

%and $f$
%\begin{align}
%	f_S(v,\varphi) = && \sum\limits_{T \in \triang} \int_T \varphi f \\
%	 				&+ &\sum\limits_{e \in \edgesb}\int_{e} \varphi \cof(D^2 w) \nabla v \cdot n \\
% &+ &\sum\limits_{e \in \edgesi}\int_{e} v \llbracket \cof(D^2 w) \nabla \varphi \cdot n\rrbracket \\
%	&-  &\sum\limits_{T \in \triang} \int_T v (\nabla \cdot \cof(D^2w)) \cdot \nabla \varphi \\
%\end{align} 

To enforce stability we enforce the following penalty terms [TICAM report 3.2.2.]
\begin{align}
	J^\sigma(\varphi, v) = \sum\limits_{e \in \edges} \int_e \frac \sigma {|e|} \jump \varphi \jump v \textnormal{ and } 	J^\sigma_0(\varphi, v) = \sum\limits_{e \in \edgesb} \int_e \frac \sigma {|e|} \varphi u_0  
\end{align}

Thus, we end up with the problem finding $v \in V_h$ such that
\[
	a_S(\phi,v) + J^\sigma(\varphi,v) = l(\varphi) + J^\sigma_0(\varphi)
\] 
$  \textnormal{for all } \varphi \in V_h$\

Just like in the finite element method we can derive a linear system of equations $A \mathbf{u} = \mathbf{b}$ with $A$ sparse and $\mathbf{u}$ representing the coefficient vector of $u_h$ to the basis $B_V$.  

\subsection{Implementation Remarks}
\todo{ Kommentar zur Implementation wegen Vorzeichen für Kantenterme}
To evaluate the integrals in the bilinearform a numerical integration scheme is needed. Usually Gauss quadrature is the method of choice. Since ansatz and test functions are chosen to be piecewise polynomials a Gauss quadrature already is exact for only a few quadrature points.
Hence, the data we have to provide to assemble the sparse matrix $A$ are the gradient, the normal derivatives, i.e. and the function values of all test functions at each quadrature point.
Suppose the 


\newpage

To apply a DG method to more difficult PDEs such as the \MA equation we need some algebraic and analytic identities for the Hessian.
\section{Hessian Identities}

\begin{definition}[Cofactor Matrix] \label{def: cof matrix}
	The \emph{cofactor matrix} of a matrix $A \in \R^{d \times d}$ is defined by the entries
	\begin{align}
	(\mycof A )_{i,j} = (-1)^{i+j} \mydet{A_{ij}},
	\end{align}
	where $A_{ij}$ denotes the matrix resulting from deleting the $i$-th row and $j$-column in $A$.
\end{definition}

In the two-dimensional case the cofactor matrix of the hessian simplifies to
\begin{align}
\mycof {D^2 u} = \begin{pmatrix}
								\dxx{x_2} u & -\frac {\partial u}{\partial x_1 x_2} \\
								-\frac {\partial u}{\partial x_2 x_1} & \frac {\partial u}{\partial x_1^2} 
							\end{pmatrix}.
\end{align}


Very advantageous is the behaviour of the cofactor matrix of a hessian if a divergence is applied to it:
\begin{definition}[Matrix Divergence]
	$\nabla \cdot A$ for a matrix $A \in ?^{d \times d}$ is defined by taking the divergence row-wise,i.e.
\[
	\nabla \cdot A = \begin{pmatrix} \nabla \cdot A_1 \\ \vdots \\ \nabla \cdot A_d\end{pmatrix}
	= \begin{pmatrix} \sum_{j = 1}^{d} \dx{x_i} A_{1,j} \\ \vdots \\ \sum_{j = 1}^{d} \dx{x_i} A_{d,j}\end{pmatrix}.
\]
	
	\todo {ueberarbeiten}
\end{definition}

\begin{lemma}[Divergence-Free Property of Cofactor Matrices] \label{la: divergence free cof}
For smooth functions $u$ the cofactor matrix of the hessian is divergence-free:
\[
	\nabla \cdot \mycof{D^2 u} = 0.
\] 
\end{lemma}
\begin{proof}
\begin{align*}
	\nabla \cdot \mycof{D^2 u} = \sum_{i=1}^{d} \dx{ x_i}\mycof{D^2 u}_i = 
	\begin{pmatrix}
		\frac {\partial^3} {\partial x_1 {x_2}^2 } -\frac {\partial^3} {\partial{x_2} x_1 {x_2}} \\
				\frac {\partial^3} {\partial {x_1}x_2 {x_1}} -\frac {\partial^3} {\partial x_2 {x_1}^2 }
	\end{pmatrix}
\end{align*}
By Schwarz' theorem the latter equals zero if $u$ is thrice continuous differentiable.
\end{proof}


\begin{lemma}[Integration by parts for the Frobenius product] \label{la: integration by parts Frobenius}
For a Frobenius product with the hessian's cofactor matrix  the following integration by parts rule holds for smooth $u$
\[
	\int_\Omega (D^2 u : B) = - \int_\Omega (\nabla \cdot B) \cdot \nabla u + \int_{\partial \Omega}  B \nabla u \bf n
\] 
\end{lemma}

\begin{proof}
The proof is based on applying integration by parts row-wise
\begin{align*}
- \int_\Omega (\nabla \cdot B) \cdot \nabla u &= 
- \int_\Omega \sum_{i = 1}^{d} (\nabla \cdot B_i) \dx {x_i} u \\
&=  \int_\Omega \sum_{i = 1}^{d} B_i \cdot  (\nabla \dx {x_i} u) - \int_{\partial \Omega} \sum_{i = 1}^{d} (B_i) \dx {x_i} u \mathbf{n} \\
&=  \int_\Omega \sum_{i = 1}^{d}\sum_{j= 1}^{d} B_{ij} \dxy {x_i}{x_j} u- \int_{\partial \Omega} B \nabla u \mathbf{n} \\
&=  \int_\Omega (D^2 u : B)- \int_{\partial \Omega} B \nabla u \mathbf{n} 
\end{align*}
\end{proof}

When later talking about weak formulation it comes handy to have a divergence form of the latter 
\begin{lemma}[Divergence form of the Frobenius Product] \label{la: An application of the divergernce product rule}
\[
		\nabla \cdot \left( \mycof {D^2 u } \nabla v \right) %- \nabla \cdot \left(\mycof {D^2 u }\right) \nabla v
		= \mycof {D^2 u}: D^2 v
\] 
\end{lemma}


\begin{lemma}[Divergence-Free Property of Cofactor Matrices]
For the Frobenius product the following integration by parts rule holds
\[
	\nabla \cdot \mycof{D^2 u} = 0
\] 
\end{lemma}


\begin{lemma}[Integration by parts for the Frobenius product]
For the Frobenius product the following integration by parts rule holds
\[
	\int_\Omega (D^2 u : B) = - \int_\Omega (\nabla \cdot B) \cdot \nabla u + \int_{\partial \Omega}  B \nabla u \boldmath n
\] 
\end{lemma}

\begin{proof}
\begin{align*}
\nabla \cdot \left( \mycof {D^2 u } \nabla v \right) =&%- \nabla \cdot \left(\mycof {D^2 u }\right) \nabla =& 
\sum_{i= 1}^{d} \dx {x_i} 	\left( \sum_{j= 1}^{d} \mycof {D^2 u }_{i,j} \dx{x_j} v \right)\\
%&-  \sum_{j= 1}^{d}  \sum_{i= 1}^{d} \left(\dx {x_i} \mycof {D^2 u }_{i,j}  \right) \dx{x_j} v \\
=&  \sum_{i= 1}^{d} \sum_{j= 1}^{d}  \left(\dx {x_i} \mycof {D^2 u }_{i,j}  \right) \dx{x_j}v + \sum_{i= 1}^{d} \sum_{j= 1}^{d}  \mycof {D^2 u }_{i,j} \dxy{x_j}{x_i}v\\
=&  \sum_{j= 1}^{d}  \nabla \cdot \left(\mycof {D^2 u }\right)_j \dx{x_j}v + \sum_{i= 1}^{d} \sum_{j= 1}^{d}  \mycof {D^2 u }_{i,j} \dxy{x_j}{x_i}v\\
=&   \nabla \cdot \left(\mycof {D^2 u }\right) \nabla v+ \mycof {D^2 u }:D^2v
\end{align*}
The hypothesis results from the fact that the cofactor matrix of the hessian is divergence-free.
\end{proof}
