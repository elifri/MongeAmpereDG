% !TeX spellcheck = de-de

\documentclass{beamer}

\usetheme{Warsaw}             % Falls Ihnen das Layout nicht gef�llt, k�nnen Sie hier
                              % auch andere Themes w�hlen. Ein Verzeichnis der m�glichen 
                              % Themes finden Sie im Kapitel 15 des beameruserguide.


\setbeamertemplate{footline}[frame number] %Seitenzahlen

\usepackage[utf8]{inputenc} % um Umlaute direkt eingeben zu
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{stmaryrd} % for llbracket
\usepackage{algorithm} %for algorithms
\usepackage{algpseudocode} %for algorithms
%\usepackage{caption}
\usepackage{subcaption} %for subfigure
\usepackage[3D]{movie15} %for interactve 3d plot 
\usepackage{hyperref}

\usepackage{bigdelim}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{ltxtable}
\usepackage{float}
%\usepackage{pgfplotstable, booktabs} %to generate tables from data files
\usepackage{cancel} %um durchzustreichen

\usepackage{natbib}
\usepackage{bibentry}

%\usepackage{bibunits} %to split bibliography

\usepackage{../Arbeit/makros}
\usepackage{todo}

\selectlanguage{ngerman}

\renewcommand{\MA}{Monge-Amp\`ere}

\makeatletter
% Detect mode. mathpalette is used to detect the used math style
\newcommand<>\Alt[2]{%
    \begingroup
    \ifmmode
        \expandafter\mathpalette
        \expandafter\math@Alt
    \else
        \expandafter\make@Alt
    \fi
    {{#1}{#2}{#3}}%
    \endgroup
}

% Un-brace the second argument (required because \mathpalette reads the three arguments as one
\newcommand\math@Alt[2]{\math@@Alt{#1}#2}

% Set the two arguments in boxes. The math style is given by #1. \m@th sets \mathsurround to 0.
\newcommand\math@@Alt[3]{%
    \setbox\z@ \hbox{$\m@th #1{#2}$}%
    \setbox\@ne\hbox{$\m@th #1{#3}$}%
    \@Alt
}

% Un-brace the argument
\newcommand\make@Alt[1]{\make@@Alt#1}

% Set the two arguments into normal boxes
\newcommand\make@@Alt[2]{%
    \sbox\z@ {#1}%
    \sbox\@ne{#2}%
    \@Alt
}

% Place one of the two boxes using \rlap and place a \phantom box with the maximum of the two boxes
\newcommand\@Alt[1]{%
    \alt#1%
        {\rlap{\usebox0}}%
        {\rlap{\usebox1}}%
    \setbox\tw@\null
    \ht\tw@\ifnum\ht\z@>\ht\@ne\ht\z@\else\ht\@ne\fi
    \dp\tw@\ifnum\dp\z@>\dp\@ne\dp\z@\else\dp\@ne\fi
    \wd\tw@\ifnum\wd\z@>\wd\@ne\wd\z@\else\wd\@ne\fi
    \box\tw@
}

\makeatother




%\titlehead{\includegraphics[height=0.5cm]{../Arbeit/rwth.pdf} \hspace{1cm}
%\includegraphics[height=0.5cm]{../Arbeit/IGPM_logo_klein.png}
%}

\subject{Master Thesis}
\title{ %Discontinuous Galerkin Methods for the \MA Equation}
%\subtitle{\Large 
Discontinuous-Galerkin-Verfahren zur Lösung der Monge-Amp\`ere-Gleichung}
\author{Elisa Friebel} %\\ Matrikelnummer: 295932
\date{\today}
%\publishers{Gutachter: Prof. Dr. rer. nat. W. Dahmen\\ Prof. Dr. rer. nat. S. Noelle}
\date{20. Januar 2015 \\[.5\baselineskip] Mastervortrag}

\begin{document}
\frame{\maketitle}

%\begin{bibunit}[plain]

\section{\MA-Gleichung}

\frame<beamer>{\frametitle{Inhalt} \tableofcontents}

\AtBeginSection[]{\frame<beamer>{\frametitle{Inhalt} \tableofcontents[current]}}

\subsection{Definition, Existenz und Eindeutigkeit}

\begin{frame}{Die \MA-Gleichung}
\begin{block}{\MA(MA)-Gleichung mit Dirichlet-Randdaten}
Sei $\Omega$ ein beschränktes Gebiet und $u:\Omega \rightarrow \R, f:\Omega \rightarrow \R$ und $g:\partial \Omega \rightarrow \R$. Dann lautet die \MA-Gleichung
 \begin{align*}
	 \mydet{D^2 u} &= f \textnormal{ in } \Omega, \\ %\label{eq: MA eq}\\
	 u & = g \textnormal{ auf } \partial \Omega. %\label{eq: MA equation dirilecht} 
 \end{align*}
 \end{block}
\pause
Anwendungsgebiete für Gleichungen vom Typ \MA
\begin{itemize}
	\item Astrophysik
	\item Differentialgeometrie
	\item Finanzwesen
	\item Optimaler Transport
	\item Optik
\end{itemize} 
\end{frame}

%\subsection{Existence and Uniqueness}
\begin{frame}{Existenz von Lösungen}
	Sei $F$ der \MA-Operator, d.h. $F= \detHess{u} - f$
	\begin{itemize}
		\item $F$ ist ein nichtlinearer Operator zweiter Ordnung
		\pause
		\item $F$ ist elliptisch für strikt konvexe Funktionen $u$ und $f > 0$. %\citep{GT1983}
		\pause
		\item Existenz von klassischen Lösungen hängt von der Regularität der rechten Seite und dem Gebiet ab
		\pause
		\item klassische Lösungen sind nicht eindeutig
		\pause
		\item keine schwache Formulierung im klassischen Sinne\\
		 $\rightarrow $ im besonderen kann der \quoting{Partielle Integrations-Ansatz} nicht übertragen werden
	\end{itemize}
\end{frame}

\begin{frame}{Schwacher Lösungsbegriff}
	\begin{block}{Viskositätslösung {\citep[Definition 1.1]{FGN2013}}}
		Wir nennen eine strikt konvexe Funktion $u \in C^0(\Omega)$ eine \emph{Viskositäts-Unterlösung(-Überlösung)} der \MA-Gleichung, falls für jeden Punkt $x_0 \in \Omega$ und jede Funktion $\varphi \in C^2(\Omega)$ mit
		\[
		   u \leq \varphi \;(\geq \varphi) \text{ in }\Omega \text{  und  } u(x_0) = \varphi(x_0)
		\] gilt, dass
		\[
			F[\varphi](x_0) \leq 0 \;(\geq 0).%\mydet{D^2 \varphi(x_0)} - f \leq 0 (\geq 0).
		\]

\end{block}
	Viskositätslösungen sind eindeutig.
	%u-\varphi hat ein maximum(minimum), d.h. DF(u-\varphi)\leq(\geq)
\end{frame}

\subsection{Numerische Verfahren}
\begin{frame}[allowframebreaks]{Numerische Verfahren}
Numerische Verfahren können in vier Kategorien eingeteilt werden \citep[p.210]{FGN2013}: 

\begin{enumerate}
	\item Methode, die Ableitungen durch Differenzenquotienten approximieren, %\footnotesize {\bibentry{FO2011}}
		\begin{itemize}
		\item finite Differenzen Schemata
%			\begin{refsection}
			z.B. \citep{FO2011}
%			 \bibentry{FO2011}
%			\printbibliography
%			\end{refsection}
		\end{itemize}
	\item Methoden, die auf variationellen Prinzipien und Approximation von unendlich-dimensionalen Räumen durch endlich-dimensionale Räume basieren
		\begin{itemize}
			\item Galerkin Methoden, wie finite Elemente Methoden, Least Square Methoden, discontinuous Galerkin (DG) Methoden, z.B. \citep{BGN+2011, Neilan2014, DG2004}
		\end{itemize}
	\item Methoden basierend auf endlichen Basiserweiterungen und Approximieren von partiellen Differentialgleichungen an Stichprobenpunkten,
		\begin{itemize}
			\item Kollokationsmethoden, z.B. \citep{BHP2014}
%			\item gitterfreie Methoden, z.B. \citep{LH2013}
		\end{itemize}
	\item Methoden, die in keiner der vorher genannten Bereiche gehören, z.B. \citep{OP1989}
\end{enumerate}

\end{frame}

\begin{frame}{Finite Differenzen Schemata (FDS)}
Standard FDS (z.B. der 9-Punkte-Stern) sind uneindeutig lösbar:\\
	Lösen des nichtlinearen System mit einem Newton-Verfahren liefert verschiedene Ergebnisse für unterschiedlich gewählte Startwerte.
\pause
\vspace{0.2cm}

Vorteile der FDS:
\begin{itemize}
	\item Schema für Konvergenzbeweise, das Konvergenz gegen die Viskositätslösung sichert \citep{BS1991}
\end{itemize}
\begin{columns}[c]
\begin{column}{0.65\textwidth}
\pause

Nachteile der FDS:
\begin{itemize}
	\item keine bewiesenen Konvergenzraten
	\item große Sterne, nicht anwendbar für viele Gebiete
	\item für höhere Genauigkeit müssen sowohl das Gitter verfeinert, als auch der Stern vergrößert werden
\end{itemize}
\end{column}

\hspace{-1cm}
\pause
\begin{column}{0.35\textwidth}
\begin{figure}
  \begin{center}
    \input{stencil17.pgf}
  \end{center}
\end{figure}

\end{column}
\end{columns}
\end{frame}

\begin{frame}{Galerkin-Methoden}
Vorteil der Galerkin-Methoden:
\begin{itemize}
	\item erweiterbar auf komplexere Gebiete
	\item geschachtelte Iterationen sind einfach zu realisieren
\end{itemize}

\pause
Nachteile der Galerkin-Methoden:
\begin{itemize}
	\item keine variationelle Formulierung der \MA-Gleichung
	\item bisher existiert kein Galerkin-Verfahren, das bewiesen gegen Viskositätslösungen konvergiert
\end{itemize}
\pause
Beispiele für Galerkin-Methoden für die \MA-Gleichung
\begin{itemize}
	{\small  
	\item \quoting{$C^{{0}}$ penalty methods for the fully nonlinear MA equation} \citep{BGN+2011}
	\item \quoting{FEM for fully nonlinear second order PDEs based
		on a discrete Hessian with applications to the MA
		equation}\citep{Neilan2014}
	}
\end{itemize}

\end{frame}

\section{Eine DG-Methode zur Lösung der \MA-Gleichung}
\subsection{Motivation}
\begin{frame}{Picard-Linearisierung}
\begin{itemize}
\item Diffusionsgleichung: $\nabla \cdot (A(u) \nabla u ) = f$
\pause
\item Entkoppeln der Koeffizientenmatrix $A(u)$ und $\nabla u$
\pause
\item für $i\in \N$ wiederholtes Lösen der Gleichungen 
	\begin{align}
	\nabla \cdot (A(u^{i} )\nabla u^{i+1}) = f \label{eq: Picard linearisation}
	\end{align}
\item \eqref{eq: Picard linearisation} ist linear in $u^{i+1}$
\pause
\item konvergiert langsamer als ein Newton-Verfahren, konvergiert für mehr Startwerte %\citep{Deblois1997}
\pause
\item Idee: eine ähnliche Linearisierung für die MA-Gleichung finden
\end{itemize}
\end{frame}

\begin{frame}{Entkoppeln der MA-Gleichung}
\begin{align*}
\visible<1->{	
	&\dyy u{x}  \dyy u{y}  -\dyx u {x}{y} \dyx u {y}{x} = f} \\
	\visible<2->{\Leftrightarrow \; &\mycof {D^2 u }:D^2 u  = 2f,}
\end{align*}
\visible<2->{dabei ist im zweidimensionalen Fall die Kofaktormatrix von $D^2 u$ definiert durch
\[
	\cofHess u = \begin{pmatrix}
		u_{yy} & - u_{xy} \\
		-u_{yx} &  u_{xx} 
	\end{pmatrix}.
\]}
\visible<3->{
Divergenz-Form:
\begin{align*}
	- \nabla \cdot \left( \mycof{ D^2 u} \nabla u \right)  = -2f
\end{align*}
}
\end{frame}

\begin{frame}{Picard-Iteration zur Lösung der MA-Gleichung}
	Sei ein Startwert $u^0$ gegeben. Löse für $i \in \N$
	\begin{align}
		- \nabla \cdot \left( \cofHess{u^i} \nabla u^{i+1} \right)  = -2f. \label{eq: Picard-Iteration}
	\end{align}

	\pause
	\begin{itemize}
		\item \eqref{eq: Picard-Iteration} ist ein verallgemeinertes Poisson  Problem (GPP)\\
			 $\rightarrow$ d.h. linear in den zweiten Ableitungen von $u^{i+1}$
		\pause
		\item unstetige Elemente, da $\cofHessH{u_h^i}$ unstetig ist (für finite Elemente, die nicht in $C^2(\Omega)$ enthalten sind)
		\pause 
		\item Symmetrisches Interior-\-Penalty-\-Galer\-kin(SIPG)\--Verfahren \citep{PPO+2000, BS2008}.
	\end{itemize}

\end{frame}

\subsection{Symmetrisches Interior-Penalty-Galerkin-Verfahren}

\begin{frame}{Diskrete variationelle Formulierung des GPP}
Sei $\triang$ eine Triangulierung von $\Omega $ und der FE-Raum \[V_h =  \{f \in L^2(\Omega);  f|_T \in \mathcal P_k (T) \text{ for every } T \in \triang\}\] gegeben. 
\pause
Aus dem GPP folgt
			\begin{align*}
				-\myIntX \Omega {v_h \nabla \cdot (A \nabla u_h)}=
				 \myIntX \Omega {v_h f} \qquad \forall v_h \in V_h. %\label{eq: variational form}
			\end{align*}
\pause
Partielle Integration auf jeder Zelle ergibt
			\begin{align*}
				%a(v, u) = & 
				\sum_{T \in \triang} \myIntX T {\nabla v_h \cdot A \nabla u_h }
					- \sum_{T \in \triang} \myIntS  {\partial T} { v_h A \nabla u_h \cdot \mathbf n}	= \sum_{T \in \triang} \myIntX T {v_h f}.
			\end{align*}
\end{frame}

\begin{frame}{Herleitung des SIPG-Verfahrens}
\alt
	{
		\alt{Symmetrisieren}
			{Vernachlässige den Sprung in $\nabla u$ wegen der Glattheit von $u$}<3->
	}
	{Summieren und Umschreiben mit Sprung und Mittelwert liefert}<2-> % we have
	\begin{align*}
				   \sum\limits_{T \in \triang} \myIntX  T { \nabla v_h \cdot A \nabla u_h} 
					& - \sum\limits_{e \in \edgesi}\myIntS {e} {
					\left(
					  \Alt 
					  	{\Alt 
					  		{\Alt
					  			 {\jump {u_h \average{ A \nabla v_h}}   }
					  			 {\textcolor{red}{\jump {u_h \average{ A \nabla v_h}}   }}<4->
					  		}
					         { \cancel{\jump {\average {v_h}  A \nabla u_h}}}<3->
					    }
					    {\jump {\average {v_h}  A \nabla u_h}}<2->
					 + \jump {v_h \average{ A \nabla u_h}} \right)}\\
				& - \sum\limits_{e \in \edgesb}
				         {\Alt 
				         	{ \myIntS {e} {\textcolor{red}{
				         			\left(
				         			  \textcolor{black}{v A \nabla u \cdot \mathbf n} + u_h A \nabla v_h \cdot \mathbf n
				         			\right)
  			         	     }}}
			  			    {\myIntS {e} {v_h A \nabla u_h \cdot \mathbf n}}<4->
			  			  }
	\end{align*}
	\Alt{$\Rightarrow$ Addiere den Term auch auf der rechten Seite}
	{}<4->
\end{frame}

\begin{frame}{Penalty-Terme für Approximation von Stetigkeit und Di\-rich\-let\--Rand\-be\-dingungen}
%	\Alt{Add penalties to enforce continuity and Dirichlet boundary conditions}{}<3>
	\begin{align*}
	a(v_h,u_h) =  &\sum\limits_{T \in \triang} \myIntX  T { \nabla v_h \cdot A \nabla u_h} \\
	  & \Alt
	  		{\Alt
	  			 { -\sum\limits_{e \in \textcolor{black}{\edges}}\myIntS e { \jump {v_h \average{A \nabla u_h} }}
	  			   - \sum\limits_{e \in \textcolor{black}{\edges}}\myIntS e { \jump{ u_h \average{ A \nabla v_h}}}}
	  			 { -\sum\limits_{e \in \textcolor{red}{\edges}}\myIntS e { \jump {v_h \average{A \nabla u_h} }}
	          	  - \sum\limits_{e \in \textcolor{red}{\edges}}\myIntS e { \jump{ u_h \average{ A \nabla v_h}}}} }<3->
	  		{ -\sum\limits_{e \in \edgesi}\myIntS e { \jump {v_h \average{A \nabla u_h} }}
	 		  - \sum\limits_{e \in \edgesi}\myIntS e { \jump{ u_h \average{ A \nabla v_h}}}}<2-> \\ 
	  & \Alt
	        {
	        	\Alt
	        		{\textcolor{red}{+\sum\limits_{e \in \edges} \myIntS e { \frac \sigma {|e|} \jump {v_h} \jump {u_h}} }}
	        		{}<3->
	        }
	  		{-\sum\limits_{e \in \edgesb}\myIntS e { v_h A \nabla u_h \cdot \mathbf n} 
	    	 - \sum\limits_{e \in \edgesb}\myIntS e { u_h A \nabla v_h \cdot \mathbf n} }<2->
	 \end{align*}
	 
	 \begin{align*}
	 	l(v_h) =& \sum\limits_{T \in \triang} \myIntX  T { v_h f}
	 		 -\sum\limits_{e \in \edgesb}\myIntS e { g A \nabla v_h \cdot \mathbf n}
	 		 \uncover<3>{\textcolor{red}{+\sum\limits_{e \in \edgesb} \myIntS e {\frac \sigma {|e|} v_h g}}}
	 \end{align*}
\end{frame}

\begin{frame}{Korrektheit des SIPG-Verfahrens}
Die Energie-Norm $\eNorm \cdot$ ist definiert durch
\[
	\eNorm v ^2 := \LTwonorm{\nabla v}^2 + \frac 1 \sigma \sum_{e \in \edges} |e|\LTwonormE{\average{\nabla v}}^2 + 2 \sigma \sum_{e \in \edges} \frac 1 {|e|}\LTwonormE{\jump{v}}^2.\]
\pause
	\begin{itemize}
		\pause
		\item $a$ ist bilinear
		\pause
		\item $a$ ist beschränkt bzgl. der Energie-Norm $\eNorm \cdot$, d.h. $a(u,v) \lesssim \eNorm u \eNorm v $
		\pause
		\item $a$ ist koerziv bzgl. der Energie-Norm $\eNorm \cdot$, falls $A$ pos. def ist und $\sigma \geq \sigma^*$, d.h. es existiert $\alpha > 0$ mit $ a(v,v) \geq \alpha  {\eNorm v}^2 \qquad \forall v \in V_h$
		\pause
		\item es existiert ein eindeutiges $u \in V_h$, so dass $a(u,v) = l(v) \qquad \forall v \in V_h$
	\end{itemize}
\end{frame}

\begin{frame}{Fehlerabschätzung für SIPG}
	\begin{block}{Lemma  \cite[Lemma 10.5.21]{BS2008}}
		Sei $u$ die exakte Lösung des GPP und $\sigma \geq \sigma^*$, so dass $a$ stabil ist. 
		Weiterhin erfülle $u_h \in V_h$
		\[
		a(v_h, u_h) = l(v_h) \qquad \forall v_h \in V_h.
		\]
		Dann existiert eine positive Konstante $C$ unabhängig von $h$, so dass
		\[
		\eNorm{u - u_h } \leq \left(1+\frac C \alpha\right) \inf_{v_h \in V_h} \eNorm{u - v_h}.
		\]
		Hierbei ist $\alpha$ die Koerzivitätskonstante von $a$. 
	\end{block}
\end{frame}


\subsection{Herausforderungen für die Picard-Iteration}
\begin{frame}{Startwert für die Picard-Iteration}
%In \citep[Remark 2.1]{DG2006a} 
Es wurde gezeigt \citep{DG2006a}, dass die Lösung von 
\begin{align*}
	\triangle u &= \sqrt{2f} \text{ in } \Omega, \\ 
	u &= g \text{ auf }\partial \Omega
\end{align*}
als eine gute Schätzung für die Lösung der MA-Gleichung dient.
\vspace{0.3cm}

\pause
Geschachtelte Iteration:
\begin{itemize}
\item auf dem gröbsten Gitter eine simple Startfunktion $u^0_{h_1}$, z.B. $\frac 1 2 ({x_1^2} + {x_2^2}) $ 
\item auf dem Gitter $\mathcal{T}_{h_{l}}$ wird als Startwert die letzte Lösung vom vorherigen Gitter genutzt
\end{itemize}
\end{frame}

\begin{frame}{Konsistenz-Test der Picard-Iteration}
Simples MA-Problem mit der klassischen Lösung $\frac 1 2 (x_1^2 + x_2^2 )$:
\begin{align*}
	\mydet {D^2 u} = 1 \text{ in } \Omega \quad \text{  und  }\quad 
	u = \frac 1 2 (x_1^2 + x_2^2 )\text{ auf }\partial \Omega
\end{align*}
%\vspace{-0.5cm}
\pause
Rel. $L^2$-Fehler auf einem Gitter mit $h=\frac 1 2$ und dem exakten Startwert $u_0=u$

\begin{figure}[H]
	\centering
	\includegraphics[trim = 2cm 4cm 1cm 4cm, scale =0.3]{../Arbeit/plots/consisctency_first_try.pdf}
	%\label{fig: consisctency_first_try}
\end{figure}
\end{frame}

\begin{frame}{Ein weiterer Penalty-Parameter}
  \begin{columns}
	\begin{column}{0.9\textwidth}
%	\begin{wrapfigure}{r}{0.5\textwidth}
		\begin{figure}[H]
			\centering
			\includegraphics[width=.7\textwidth]{../Arbeit/plots/sharp_edges.png}
%			\includemovie[ 
%			 poster,controls, 
%			 label=mylabel]{5cm}{5cm}{sharp_edges.u3d} 
%			\caption{Numerische Lösung}
			\label{fig: sharp edges}
%	\end{wrapfigure}
		\end{figure}
	\end{column}
	\hspace{-2cm}
	\pause
	\begin{column}{0.3\textwidth}
%		\todo{.vtu file?}
		\begin{itemize}
			\item scharfe Kanten
			\item hängt von der Triangulierung ab, obwohl die Lösung in $V_h$ enthalten
		\end{itemize}
	\end{column}
  \end{columns}
\end{frame}

\begin{frame}{Ein weiterer Penalty-Parameter}
\begin{itemize}
\item mehr Regularität in der ersten Ableitung fordern
\pause
\item Neilan benutzt in seiner DG-Methode \citep{Neilan2014} für kleine Polynomgrade einen zusätzlichen Penalty-Term
\end{itemize}
\[
	\sum_{e \in \edgesi} \sigma^G |e |\myIntS e {\jump{ \nabla u} \jump {\nabla v}}
\]
\pause
$\Rightarrow$ die so verbesserte Methode besteht den vorher erwähnten Konsistenz-Test ($\sigma^G$ =50)
\end{frame}

\begin{frame}{Ein weiterer Penalty-Parameter}

	\begin{figure}[H]
	\begin{subfigure}[b]{.45\textwidth}
		\includegraphics[width=1.\textwidth]{../Arbeit/plots/with_penalty_it22.pdf}
		\caption{Lösung nach 23 Iterationen}
	\end{subfigure}
	~
	\begin{subfigure}[b]{.45\textwidth}
		\includegraphics[width=1.\textwidth]{../Arbeit/plots/with_penalty_it23.pdf}
		\caption{Lösung nach 24 Iterationen}
	\end{subfigure}
	\caption{Die Lösung zweier aufeinander folgender Iterationen}
	\end{figure}
\end{frame}

\begin{frame}{Dämpfung der Picard-Iteration}
Relativer $L^2$-Fehler auf einem Gitter mit $h=\frac 1 4$ und zusätzlichem Gradient-Penalty-Term
	\begin{figure}[H]
		\centering
		\includegraphics[trim = 2cm 4cm 1cm 4cm, height = 0.6\textheight]{../Arbeit/plots/oscillation.pdf}
%		\caption{Relative $L^2$ error on a grid with $h=\frac 1 4$ and gradient penalty}
		\label{fig: oscillation}
	\end{figure}
	\pause
	\vspace{-0.5cm}
	$\Rightarrow$ Konvexkombination $ \alpha u_h^{i+1} + (1- \alpha) u_h^i$ für $\alpha \in (0,1)$
\end{frame}


\begin{frame}{Korrektheit der SIPG-Formulierung}
\begin{itemize}
	\item die SIPG-Bilinearform ist nur koerziv für $\sigma > \sigma^*$
	\pause
	
	\item $\sigma^*$ hängt von $1/\lambda(\cofHess u)$ ab, hierbei bezeichnet $\lambda(A)$ den kleinsten Eigenwert einer Matrix $A$
\end{itemize}
	\pause
	$\Rightarrow$ Skaliere $\sigma$ mit $\frac 1 {\lambda^*}$,  wobei $\lambda^*$ eine Approximation des kleinsten Eigenwertes $\cofHess u$ ist. \pause 
	
	Wir wählen
	\begin{block}{Approximation von $\lambda(\cofHess u)$}
	Sei $Q$ die Menge aller Quadraturpunkte der SIPG-Methode. Dann definieren wir
	\[
		\lambda^* = \min_{q \in Q} \lambda(\cofHess {u_h(q)}).
	\]
	\end{block} 	
\end{frame}

\begin{frame}{Korrektheit der SIPG-Formulierung}
\begin{itemize}
	\item für die Koerzivität der SIPG-Bilinearform muss $\mycof {D^2_h u_h}$ positiv definit sein\\
	\item je kleiner der kleinste Eigenwert von $\mycof {D^2_h u_h}$, desto kleiner ist die Koerzivitätskonstante $\alpha$
	\pause
	\item beschränke den kleinsten Eigenwert von $\mycof {D^2_h u_h}$ von unten mit einer positiven Konstante $\varepsilon$
\end{itemize}
	\pause
	\begin{block}{Modifizierte Kofaktormatrix}
		\[ 
			\mycofMod {D^2_h u_h} = \begin{cases}
			\mycof {D^2_h u_h} & \lambda \geq \varepsilon	\\
			\mycof {D^2_h u_h}+ (-\lambda+\varepsilon) Id%\begin{pmatrix} -\lambda+\varepsilon & 0 \\ 0 & -\lambda+\varepsilon \end{pmatrix} 
			& else
			\end{cases}
		\]
	\end{block}
	\pause
	\[
		\mycof {D^2_h u_h} \text{ pos. def.} \Leftrightarrow \hess u \text{ pos. def.} \pause \Leftrightarrow u_h \text{ ist konvex}
	\]
	
\end{frame}



\begin{frame}{Konvexifizierung von Zwischenlösungen}
\begin{itemize}
	\item \MA-Gleichungen haben im Allgemeinen keine eindeutige Lösung
	\item in vielen Anwendungen wird die (eindeutige) konvexe Lösung gesucht
\end{itemize} 
\pause
	$\Rightarrow$ konvexifiziere die Lösung nach jedem Schritt
\begin{itemize}
\pause
	\item Zusammenhang zwischen Konvexität und B\'ezier-Polynomen
	\item Konvexifizierung ist nicht einfach
	\item Diskussion in den numerischen Ergebnissen
\end{itemize} 
\end{frame}

%\begin{frame}{Convexification Approach of Schumaker and Speleers{, \citep{SS2014}}}
%	Given the solution of the generalised Poisson problem $u^{gp}_h$ we seek for a convex spline minimising the error at the B\'ezier control points, i.e. 
%\begin{block}{Quadratic Program for Convexification}
%Find the B\'ezier coefficients $c$ minimising
%	\begin{align*}
%			\lVert A c - b \rVert_2, \qquad \text{ such that } Cc \geq 0. %\label{eq: convex lsq}
%	\end{align*}
%\end{block}
%\begin{itemize}
%	\item $A$ is the matrix evaluating the piecewise polynomial at the B\'ezier control points
%	\item $b$ are the function values of $u^{gp}_h$ at the B\'ezier control points
%	\item  $C$ is the matrix containing the conditions ensuring convexity on the whole domain
%\end{itemize}
%
%\end{frame}


%\subsection{Algorithm for the Picard-Iteration}

\begin{frame}
\begin{algorithm}[H]
\begin{algorithmic}
\Require Triangulation \triang, min. Gitterweite $H$, max. Anzahl an Zwischenschritten $i_{max}$
\State $u^{0}\gets $ Lösung von $
	\triangle u = \sqrt{2f} \text{ in } \Omega $ mit $
	u = g \text{ auf }\partial \Omega$ %\Comment initialisation
\While {$h < H$}
	\For {$i$ von 1 bis $i_{max}$}
		\State $\sigma \gets \sigma /\lambda^*(\cofHess{u^{i-1}}) $
		\State $u^i \gets$ Lösung des GPP mit mod. Kofaktormatrix
		\State (konvexifizieren)
		\State $u^i \gets \alpha u^{i} + (1-\alpha)u^{i-1} $ \Comment Konvexkombination
	\EndFor
	\State $h, \triang, u^{0} \gets h/2, \triangFine, u^{i_{max}}$
\EndWhile
\end{algorithmic}
\caption{Picard-Iteration-Algorithmus für die MA-Gleichung}
\label{alg: final}
\end{algorithm}
\end{frame}


\section{Numerische Ergebnisse}

\subsection{Implementierung}
\begin{frame}{Implementierung}
	\begin{itemize}
		\item implementiert in C++
		\item lineares Gleichungssystem wird direkt mit einer Choleskyzerlegung gelöst
		\item Konvexifizierung mittels eines quadratischen Programms(c.f. {\citep{SS2014}}), das mit der C++-Bibliothek IPOPT gelöst wird
		\item 15 Iteration auf jedem Gitter vor Gitterverfeinerung
		\item uniforme Standard Gitterverfeinerung
	\end{itemize}
\end{frame}

\subsection{Ergebnisse mit Konvexifizierung}
\begin{frame}{Glattes Testproblem}
\vspace{-0.5cm}
\[
	u=\exp( \lVert x \rVert_2^2  /2) 
	\text { und } 
	f = (1 + \lVert x \rVert_2^2) \exp( \lVert x \rVert^2).
\]
\vspace{-0.75cm}
\begin{figure}[H]
\centering
	\includegraphics[height=0.75\textheight]{MA1_convexify_cropped.pdf}
%	\caption{$L^2$ errors for Test \ref{test smooth} and additional convexification}
\end{figure}
\end{frame}

\begin{frame}{Einfluss der Konvexifizierung}
Vergleich des $L^2$-Fehlers bevor und nach der Konvexifizierung
\vspace{-0.75cm}
\begin{figure}[H]
	\centering
	\includegraphics[height=0.95\textheight]{../Arbeit/plots/MA1_convexComp.pdf}
\end{figure}
\end{frame}

\subsection{Ergebnisse ohne Konvexifizierung}
\begin{frame}{Glattes Testproblem ohne Konvexifizierung}
%\end{block}
\vspace{-0.75cm}
	\begin{figure}[H]
	\centering
	\includegraphics[ %trim = 3cm 4cm 0cm 2cm,
	width=\textwidth]{../Arbeit/plots/MA1.pdf}
%		\caption{$L^2$ error with grad penalty}
	\end{figure}
\end{frame}

\begin{frame}{Penalty-Parameter $\sigma^G$}
$L^2$-Fehler für verschiedene Wahlen von $\sigma^G$
\vspace{-0.75cm}
\begin{figure}[H]
	\centering
	\includegraphics[height=0.95\textheight]{../Arbeit/plots/MA1_deg2_sigma.pdf}\end{figure}
\end{frame}

\begin{frame}{Konvexkombination mit Parameter $\alpha$}
$L^2$-Fehler für verschiedene Wahlen von $\alpha$
\vspace{-0.75cm}
\begin{figure}[H]
	\centering
	\includegraphics[height=0.95\textheight]{../Arbeit/plots/MA1_deg2_alpha.pdf}\end{figure}
\end{frame}

\begin{frame}{$C^1$-Testproblem}
\vspace{-0.5cm}
\[
	u=\frac 1 2 \left( \max 0 {\lVert x - x_0 \rVert_2-0.2 }  \right)^2 
	\text { und } 
	f = \max 0 {1-\frac {0.2} {\lVert x - x_0 \rVert_2} }.
\]
\vspace{-0.75cm}
\begin{figure}[H]
\centering
	\includegraphics[height=0.85\textheight]{../Arbeit/plots/MA2.pdf}
%	\caption{$L^2$ errors for Test \ref{test smooth} and additional convexification}
\end{figure}
\end{frame}

\begin{frame}{Singuläres Testproblem}
\vspace{-0.5cm}
\[
	u = - \sqrt{ 2-  \lVert x \rVert_2^2}
	\text { und } 
	f = 2\left( 2-  \lVert x \rVert_2^2 \right)^{-2}
\]
\vspace{-0.75cm}
\begin{figure}[H]
\centering
	\includegraphics[height=0.85\textheight]{../Arbeit/plots/MA3.pdf}
%	\caption{$L^2$ errors for Test \ref{test smooth} and additional convexification}
\end{figure}
\end{frame}


\section{Fazit und Ausblick}

\begin{frame}{Fazit}
	\begin{itemize}
		\item Herleitung einer neuen DG-Methode mittels einer Picard-Linearisierung
		\item Untersuchung verschiedener Verbesserungen der Picard-DG-Methode
		\item die Picard-Iteration konvergiert auf groben Gittern, ist jedoch instabil auf feinen Gittern
		\item Überblick über aktuelle DG-Methoden
		\item aktuelle DG-Methoden geeignet für Probleme mit glatten Lösungen, in anderen Fällen müssen Konfigurationsparameter sehr sorgfältig gewählt werden und trotzdem gibt es oft keine Konvergenz
	\end{itemize}
\end{frame}

%\subsection{Conclusion}
	
\begin{frame}{Perspektive}
	\begin{itemize}
		\item Lösungen der entkoppelten PDG, insbesondere ob es weitere Lösungen als $v=w$ gibt
		\item implementierte Konvexifizierung nicht brauchbar, möglicherweise nur anwendbar auf feineren Gittern
		\item Analysis des Einflusses des Gradienten-Penalty-Terms
		\item Anwendung der Theorie, die für Picard-Linearisierungen von Diffusionstermen entwickelt wurde
		\item Erweiterung auf rechte Seiten, die von $u$ und $\nabla u$ abhängen, sowie kompliziertere linke Seiten
		\item dreidimensionaler Fall
	\end{itemize}
\end{frame}

%make next frame smaller
\def\bibfont{\scriptsize}

\begin{frame}[allowframebreaks]{Literatur}  %[allowframebreaks]
\bibliographystyle{plainnat}
\bibliography{my_additional_bibliography.bib}
%\putbib[../Arbeit/my_additional_bibliography.bib]
\end{frame}
%\end{bibunit}


\end{document}